{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import fasttext.util\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(\"./ubertext.fiction_news_wikipedia.filter_rus+short.tokens.txt.algo-cbow.epochs-15.subwords-2..5.neg_sampling-15.bin\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NON_PROPAGANDA NEWS LOADING\n",
    "\n",
    "non_propaganda_news = [\"./dataset/pravda_articles.csv\", \"./dataset/ukrinform.csv\"]\n",
    "df_non_prop = pd.read_csv(\"./dataset/tsn_articles.csv\", delimiter=\"\\t\", lineterminator=\"\\n\")\n",
    "\n",
    "df_non_prop.columns =[\"number\", \"Article\"]\n",
    "for f_ in non_propaganda_news:\n",
    "    new_file = pd.read_csv(f_, delimiter=\"\\t\")\n",
    "    new_file.columns =[\"number\", \"Article\"]\n",
    "    df_non_prop = pd.concat([df_non_prop, new_file], ignore_index=True, axis=0)\n",
    "\n",
    "df_non_prop.columns = [\"class\", \"article\"]\n",
    "df_non_prop[\"class\"] = [0]*len(df_non_prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       class                                            article\n0          1  Російські нафта і газ підтримують позитивний б...\n1          1  Фінансування Мінкульту не буде переглянуто у р...\n2          1  Соратниця Санду пішла з виборів через скандал ...\n3          1  Супутникова система, що прибула в Україну. Фот...\n4          1  контейнеровоз, що сів на мілину, шість днів бл...\n...      ...                                                ...\n16412      1   112.uaОлена  ГолубєваЖурналіст,  112.uaНезаба...\n16413      1   Топ-Новина  Журналісти  незаконно  закритих  ...\n16414      1   Починаючи  з  6  лютого  середньодобова  темп...\n16415      1   Починаючи  з  6  лютого  середньодобова  темп...\n16416      1   Починаючи  з  6  лютого  середньодобова  темп...\n\n[16417 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Російські нафта і газ підтримують позитивний б...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Фінансування Мінкульту не буде переглянуто у р...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Соратниця Санду пішла з виборів через скандал ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Супутникова система, що прибула в Україну. Фот...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>контейнеровоз, що сів на мілину, шість днів бл...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16412</th>\n      <td>1</td>\n      <td>112.uaОлена  ГолубєваЖурналіст,  112.uaНезаба...</td>\n    </tr>\n    <tr>\n      <th>16413</th>\n      <td>1</td>\n      <td>Топ-Новина  Журналісти  незаконно  закритих  ...</td>\n    </tr>\n    <tr>\n      <th>16414</th>\n      <td>1</td>\n      <td>Починаючи  з  6  лютого  середньодобова  темп...</td>\n    </tr>\n    <tr>\n      <th>16415</th>\n      <td>1</td>\n      <td>Починаючи  з  6  лютого  середньодобова  темп...</td>\n    </tr>\n    <tr>\n      <th>16416</th>\n      <td>1</td>\n      <td>Починаючи  з  6  лютого  середньодобова  темп...</td>\n    </tr>\n  </tbody>\n</table>\n<p>16417 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PROPAGANDA NEWS LOADING\n",
    "\n",
    "propaganda_news = [\"./dataset/0strana_articles.csv\", \"./dataset/newsone.csv\", \"./dataset/112.csv\"]\n",
    "\n",
    "df_prop = pd.DataFrame(columns=[\"number\", \"Article\"])\n",
    "for f_ in propaganda_news:\n",
    "    new_file = pd.read_csv(f_, delimiter=\"\\t\")\n",
    "    new_file.columns =[\"number\", \"Article\"]\n",
    "    df_prop = pd.concat([df_prop, new_file], ignore_index=True, axis=0)\n",
    "df_prop.columns = [\"class\", \"article\"]\n",
    "df_prop[\"class\"] = [1]*len(df_prop)\n",
    "df_prop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "               0         1         2         3         4         5         6  \\\n0       0.053785  0.030771 -0.024119  0.017724  0.012248  0.049205  0.040134   \n1       0.060539  0.036665  -0.01827  0.020474  0.031075  0.039284  0.052787   \n2       0.045141  0.038666  -0.00998  0.021052  0.019275  0.033237  0.029213   \n3       0.048836   0.01772 -0.020393    0.0022  0.023625  0.037664  0.040669   \n4        0.05222  0.018972 -0.007758  0.011744  0.015459  0.033291  0.032425   \n...          ...       ...       ...       ...       ...       ...       ...   \n144999   0.05662  0.027371  -0.02626  0.048068  0.027356  0.042534  0.033864   \n145000  0.059505  0.022722  -0.02149  0.019147  0.026896  0.042152  0.050826   \n145001  0.031304  0.015849 -0.009609  0.012811  0.018374  0.040383  0.042436   \n145002  0.061459  0.020769 -0.011358  0.018487   0.02958   0.04011  0.046455   \n145003  0.054429  0.030469 -0.022557  0.041039  0.025966  0.046193  0.026975   \n\n               7         8         9  ...       291       292       293  \\\n0      -0.007578  0.022239 -0.011448  ...  0.024128  0.010302   0.01164   \n1      -0.010481  0.038217 -0.014943  ...   0.02307  0.023217  0.019742   \n2      -0.024069  0.013772  0.002028  ...  0.030286   0.01986  0.019684   \n3      -0.006856    0.0373 -0.004788  ...  0.025089  0.015195  0.018691   \n4      -0.005831  0.025484  0.000944  ...  0.019612  0.009173  0.021169   \n...          ...       ...       ...  ...       ...       ...       ...   \n144999 -0.016754  0.003167  0.001174  ...  0.016539  0.003711  0.032465   \n145000 -0.008525  0.023968  0.000975  ...  0.014374  0.014451  0.025345   \n145001 -0.005907  0.008896  0.010836  ...  0.028376   0.01423  0.018503   \n145002 -0.008975  0.031053 -0.003237  ...  0.016222  0.020005   0.02484   \n145003 -0.017682  0.020781 -0.000539  ...  0.026797  0.008971  0.010081   \n\n             294       295       296       297       298       299 class  \n0      -0.068097 -0.000891  0.022995  0.014834 -0.011634 -0.000477     1  \n1      -0.073852  0.020249  0.030565  0.013555 -0.018821  -0.00516     1  \n2      -0.057726  0.018682  0.026395 -0.000498  0.026569  -0.00517     1  \n3      -0.062463  0.011937  0.021975  0.009584  -0.01079 -0.001798     1  \n4      -0.056847  0.012908  0.030069  0.012719 -0.006473 -0.002318     1  \n...          ...       ...       ...       ...       ...       ...   ...  \n144999 -0.059208  0.022664  0.046177   0.00574 -0.002303 -0.000775     0  \n145000 -0.065596  0.021373   0.03065  0.015581 -0.019273   0.00482     0  \n145001 -0.067944  0.010874  0.020956  0.007556 -0.006693  0.010351     0  \n145002 -0.061148   0.01588  0.034496  0.009945 -0.024901  0.002021     0  \n145003 -0.051957   0.02537  0.044403  0.017643 -0.003638  0.001724     0  \n\n[145004 rows x 301 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.053785</td>\n      <td>0.030771</td>\n      <td>-0.024119</td>\n      <td>0.017724</td>\n      <td>0.012248</td>\n      <td>0.049205</td>\n      <td>0.040134</td>\n      <td>-0.007578</td>\n      <td>0.022239</td>\n      <td>-0.011448</td>\n      <td>...</td>\n      <td>0.024128</td>\n      <td>0.010302</td>\n      <td>0.01164</td>\n      <td>-0.068097</td>\n      <td>-0.000891</td>\n      <td>0.022995</td>\n      <td>0.014834</td>\n      <td>-0.011634</td>\n      <td>-0.000477</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.060539</td>\n      <td>0.036665</td>\n      <td>-0.01827</td>\n      <td>0.020474</td>\n      <td>0.031075</td>\n      <td>0.039284</td>\n      <td>0.052787</td>\n      <td>-0.010481</td>\n      <td>0.038217</td>\n      <td>-0.014943</td>\n      <td>...</td>\n      <td>0.02307</td>\n      <td>0.023217</td>\n      <td>0.019742</td>\n      <td>-0.073852</td>\n      <td>0.020249</td>\n      <td>0.030565</td>\n      <td>0.013555</td>\n      <td>-0.018821</td>\n      <td>-0.00516</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.045141</td>\n      <td>0.038666</td>\n      <td>-0.00998</td>\n      <td>0.021052</td>\n      <td>0.019275</td>\n      <td>0.033237</td>\n      <td>0.029213</td>\n      <td>-0.024069</td>\n      <td>0.013772</td>\n      <td>0.002028</td>\n      <td>...</td>\n      <td>0.030286</td>\n      <td>0.01986</td>\n      <td>0.019684</td>\n      <td>-0.057726</td>\n      <td>0.018682</td>\n      <td>0.026395</td>\n      <td>-0.000498</td>\n      <td>0.026569</td>\n      <td>-0.00517</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.048836</td>\n      <td>0.01772</td>\n      <td>-0.020393</td>\n      <td>0.0022</td>\n      <td>0.023625</td>\n      <td>0.037664</td>\n      <td>0.040669</td>\n      <td>-0.006856</td>\n      <td>0.0373</td>\n      <td>-0.004788</td>\n      <td>...</td>\n      <td>0.025089</td>\n      <td>0.015195</td>\n      <td>0.018691</td>\n      <td>-0.062463</td>\n      <td>0.011937</td>\n      <td>0.021975</td>\n      <td>0.009584</td>\n      <td>-0.01079</td>\n      <td>-0.001798</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.05222</td>\n      <td>0.018972</td>\n      <td>-0.007758</td>\n      <td>0.011744</td>\n      <td>0.015459</td>\n      <td>0.033291</td>\n      <td>0.032425</td>\n      <td>-0.005831</td>\n      <td>0.025484</td>\n      <td>0.000944</td>\n      <td>...</td>\n      <td>0.019612</td>\n      <td>0.009173</td>\n      <td>0.021169</td>\n      <td>-0.056847</td>\n      <td>0.012908</td>\n      <td>0.030069</td>\n      <td>0.012719</td>\n      <td>-0.006473</td>\n      <td>-0.002318</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>144999</th>\n      <td>0.05662</td>\n      <td>0.027371</td>\n      <td>-0.02626</td>\n      <td>0.048068</td>\n      <td>0.027356</td>\n      <td>0.042534</td>\n      <td>0.033864</td>\n      <td>-0.016754</td>\n      <td>0.003167</td>\n      <td>0.001174</td>\n      <td>...</td>\n      <td>0.016539</td>\n      <td>0.003711</td>\n      <td>0.032465</td>\n      <td>-0.059208</td>\n      <td>0.022664</td>\n      <td>0.046177</td>\n      <td>0.00574</td>\n      <td>-0.002303</td>\n      <td>-0.000775</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>145000</th>\n      <td>0.059505</td>\n      <td>0.022722</td>\n      <td>-0.02149</td>\n      <td>0.019147</td>\n      <td>0.026896</td>\n      <td>0.042152</td>\n      <td>0.050826</td>\n      <td>-0.008525</td>\n      <td>0.023968</td>\n      <td>0.000975</td>\n      <td>...</td>\n      <td>0.014374</td>\n      <td>0.014451</td>\n      <td>0.025345</td>\n      <td>-0.065596</td>\n      <td>0.021373</td>\n      <td>0.03065</td>\n      <td>0.015581</td>\n      <td>-0.019273</td>\n      <td>0.00482</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>145001</th>\n      <td>0.031304</td>\n      <td>0.015849</td>\n      <td>-0.009609</td>\n      <td>0.012811</td>\n      <td>0.018374</td>\n      <td>0.040383</td>\n      <td>0.042436</td>\n      <td>-0.005907</td>\n      <td>0.008896</td>\n      <td>0.010836</td>\n      <td>...</td>\n      <td>0.028376</td>\n      <td>0.01423</td>\n      <td>0.018503</td>\n      <td>-0.067944</td>\n      <td>0.010874</td>\n      <td>0.020956</td>\n      <td>0.007556</td>\n      <td>-0.006693</td>\n      <td>0.010351</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>145002</th>\n      <td>0.061459</td>\n      <td>0.020769</td>\n      <td>-0.011358</td>\n      <td>0.018487</td>\n      <td>0.02958</td>\n      <td>0.04011</td>\n      <td>0.046455</td>\n      <td>-0.008975</td>\n      <td>0.031053</td>\n      <td>-0.003237</td>\n      <td>...</td>\n      <td>0.016222</td>\n      <td>0.020005</td>\n      <td>0.02484</td>\n      <td>-0.061148</td>\n      <td>0.01588</td>\n      <td>0.034496</td>\n      <td>0.009945</td>\n      <td>-0.024901</td>\n      <td>0.002021</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>145003</th>\n      <td>0.054429</td>\n      <td>0.030469</td>\n      <td>-0.022557</td>\n      <td>0.041039</td>\n      <td>0.025966</td>\n      <td>0.046193</td>\n      <td>0.026975</td>\n      <td>-0.017682</td>\n      <td>0.020781</td>\n      <td>-0.000539</td>\n      <td>...</td>\n      <td>0.026797</td>\n      <td>0.008971</td>\n      <td>0.010081</td>\n      <td>-0.051957</td>\n      <td>0.02537</td>\n      <td>0.044403</td>\n      <td>0.017643</td>\n      <td>-0.003638</td>\n      <td>0.001724</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>145004 rows × 301 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMBINING DATASETS TO GET A VECTOR MATRIX\n",
    "len_prop, len_non_prop = len(df_prop), len(df_non_prop)\n",
    "df_combined = pd.concat([df_prop, df_non_prop], ignore_index=True)\n",
    "\n",
    "l = len(df_combined)\n",
    "df_features = pd.DataFrame(columns=list(range(300))+[\"class\"], index=list(range(l)))\n",
    "for i in range(l):\n",
    "    df_features.iloc[i, :-1] = model.get_sentence_vector(df_combined.loc[i, \"article\"])\n",
    "    df_features.loc[i, \"class\"] = df_combined.loc[i, \"class\"]\n",
    "df_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[ 0.06091989,  0.74803935,  1.52852962, ...,  0.12723808,\n          0.54915438,  0.13086457],\n        [ 0.31471053, -0.57911948,  0.18603503, ...,  1.02621107,\n          1.4703906 ,  0.77954306],\n        [-0.56095502, -0.27487681, -1.2589241 , ..., -1.5739782 ,\n         -0.33624449, -0.9574096 ],\n        ...,\n        [ 0.10018549,  1.39557612,  0.55528058, ..., -0.03634658,\n          1.09532672, -0.30622785],\n        [ 0.48924609, -0.94552226,  0.76858958, ...,  1.80493491,\n         -0.31021141,  1.49582015],\n        [ 0.77088237, -1.07485255,  0.8803184 , ...,  0.0533789 ,\n          0.85094062,  0.73035258]]),\n 24145     0\n 42206     0\n 198       1\n 33474     0\n 26193     0\n          ..\n 41861     0\n 25461     0\n 133691    0\n 111586    0\n 68183     0\n Name: class, Length: 29001, dtype: int64)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPLITTING TRAIN\\TEST SAMPLES\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features.iloc[:, :-1], df_features[\"class\"], test_size=0.20, random_state=42, shuffle=True)\n",
    "y_train, y_test = y_train.astype(int), y_test.astype(int)\n",
    "X_train, X_test = X_train.astype(float), X_test.astype(float)\n",
    "X_train, X_test = preprocessing.StandardScaler().fit_transform(X_train), preprocessing.StandardScaler().fit_transform(X_test)\n",
    "X_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116003,)\n",
      "(116003, 300)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def print_report(model, y_true, predictions):\n",
    "    conf = confusion_matrix(y_true, predictions)\n",
    "    acc = accuracy_score(y_true, predictions)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, predictions)\n",
    "    precision = precision_score(y_true, predictions, zero_division=0)\n",
    "    recall = recall_score(y_true, predictions, zero_division=0)\n",
    "    f1 = f1_score(y_true, predictions, zero_division=0)\n",
    "    print(\"Results for: \", model)\n",
    "    print(\"Confusion matrix:\\n\", conf)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"Balanced accuracy: \", balanced_acc)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  LogisticRegression()\n",
      "Confusion matrix:\n",
      " [[25324   420]\n",
      " [  736  2521]]\n",
      "Accuracy:  0.9601393055411882\n",
      "Balanced accuracy:  0.878855347749352\n",
      "Precision:  0.8571914314858892\n",
      "Recall:  0.7740251765428309\n",
      "F1:  0.813488222007099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marta/code/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_without_cross_validation(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print_report(model, y_test, predictions)\n",
    "    return model\n",
    "test_model_without_cross_validation(LogisticRegression())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"DecisionTreeClassifier\": {\"max_depth\":[5, 7, 8, 10],\n",
    "                              \"min_samples_split\": [3, 2, 4],\n",
    "                              \"min_samples_leaf\": [5, 10, 20],\n",
    "                              \"min_weight_fraction_leaf\": [0.5, 0.10, 0.15],\n",
    "                              \"max_features\": [5, 7, 10]\n",
    "                              },\n",
    "    \"RandomForest\": {\"n_estimators\": [20, 50, 100, 120],\n",
    "                     \"max_features\": [5, 9, 12],\n",
    "                     \"max_depth\": [5, 7, 10, 15],\n",
    "                     \"min_samples_leaf\": [5, 10, 15]\n",
    "                    },\n",
    "    \"KNN\":  {'n_neighbors':[9, 10, 12],\n",
    "             'leaf_size': [20, 30, 50]\n",
    "             },\n",
    "    \"AdaBoostClassifier\": {\"n_estimators\": [20, 50, 100, 120],\n",
    "                            \"learning_rate\": [0.005, 0.01, 0.03]\n",
    "                            },\n",
    "    \"GradientBoostingClassifier\": {\"n_estimators\": [20, 50, 100, 120],\n",
    "                            \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "                            \"min_samples_leaf\": [5, 10, 20],\n",
    "                            \"max_features\": [5, 7, 10]\n",
    "                            }\n",
    "\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def test_estimator(estimator):\n",
    "    estimator.fit(X_train, y_train.astype(int))\n",
    "    y_pred_ = estimator.predict(X_test)\n",
    "    print_report(estimator, y_test, y_pred_)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def test_best_model(model, param_dict, cv=5):\n",
    "    g = GridSearchCV(model, param_dict, cv=cv).fit(X_train, y_train)\n",
    "    m = g.best_estimator_\n",
    "    preds = m.predict(X_test)\n",
    "    print_report(m, y_test, preds)\n",
    "    return g.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  DecisionTreeClassifier(max_depth=5, max_features=5, min_samples_leaf=5,\n",
      "                       min_samples_split=3, min_weight_fraction_leaf=0.5)\n",
      "Confusion matrix:\n",
      " [[25744     0]\n",
      " [ 3257     0]]\n",
      "Accuracy:  0.8876935278093859\n",
      "Balanced accuracy:  0.5\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1:  0.0\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = test_best_model(DecisionTreeClassifier(),  params[\"DecisionTreeClassifier\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  KNeighborsClassifier(leaf_size=20, n_neighbors=10)\n",
      "Confusion matrix:\n",
      " [[24940   804]\n",
      " [ 1531  1726]]\n",
      "Accuracy:  0.9194855349815524\n",
      "Balanced accuracy:  0.7493524727445577\n",
      "Precision:  0.6822134387351778\n",
      "Recall:  0.5299355234878723\n",
      "F1:  0.596509417660273\n"
     ]
    },
    {
     "data": {
      "text/plain": "KNeighborsClassifier(leaf_size=20, n_neighbors=10)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_best_model(KNN(), params[\"KNN\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for:  AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5,\n",
      "                                                         max_features=5,\n",
      "                                                         min_samples_leaf=5,\n",
      "                                                         min_samples_split=3,\n",
      "                                                         min_weight_fraction_leaf=0.5),\n",
      "                   learning_rate=0.005, n_estimators=20)\n",
      "Confusion matrix:\n",
      " [[25744     0]\n",
      " [ 3257     0]]\n",
      "Accuracy:  0.8876935278093859\n",
      "Balanced accuracy:  0.5\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5,\n                                                         max_features=5,\n                                                         min_samples_leaf=5,\n                                                         min_samples_split=3,\n                                                         min_weight_fraction_leaf=0.5),\n                   learning_rate=0.005, n_estimators=20)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_best_model(AdaBoostClassifier(best_tree_model),  params[\"AdaBoostClassifier\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_best_model(GradientBoostingClassifier(),  params[\"GradientBoostingClassifier\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_best_model(RandomForestClassifier(),  params[\"RandomForest\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}